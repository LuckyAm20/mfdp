version: "3.8"
volumes:
  frontend_dist:
services:
  backend:
    build:
      context: ./app/backend/
      dockerfile: Dockerfile
    container_name: backend
    volumes:
      - ./data:/app/backend/data
      - ./models:/app/backend/models
    ports:
      - "8000:8000"
    env_file:
      - .env
    depends_on:
      database:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
    restart: on-failure

  database:
    image: postgres:16
    container_name: postgres_db
    env_file:
      - .env
    volumes:
      - ./data/postgres:/var/lib/postgresql/data
      - ./airflow/init_db:/docker-entrypoint-initdb.d
    expose:
      - 5432
    restart: unless-stopped
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U postgres" ]
      interval: 10s
      timeout: 5s
      retries: 5

  rabbitmq:
    image: rabbitmq:3-management
    container_name: rabbitmq
    env_file:
      - .env
    volumes:
      - ./data/rabbitmq:/var/lib/rabbitmq
    ports:
      - '5672:5672'
      - '15672:15672'
    restart: on-failure
    healthcheck:
      test: [ "CMD", "rabbitmqctl", "status" ]
      interval: 10s
      timeout: 5s
      retries: 5

  worker:
    build:
      context: ./app/backend
      dockerfile: ./workers/Dockerfile
    env_file:
      - .env
    volumes:
      - ./data:/app/backend/data
      - ./models:/app/backend/models
      - ./logs:/logs
    depends_on:
      database:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
    deploy:
      replicas: 2
    restart: on-failure

  frontend:
    image: node:20-alpine
    container_name: frontend_builder
    working_dir: /usr/src/app
    volumes:
      - ./app/frontend:/usr/src/app
      - frontend_dist:/usr/share/nginx/html
    env_file:
      - .env
    command: >
      /bin/sh -c "
        npm ci &&
        npm run build &&
        rm -rf /usr/share/nginx/html/* &&
        cp -r dist/* /usr/share/nginx/html/
      "
    restart: "no"

  nginx_proxy:
      image: nginx:stable-alpine
      container_name: nginx_proxy
      ports:
        - '80:80'
      volumes:
        - frontend_dist:/usr/share/nginx/html:ro
        - ./nginx/nginx.conf:/etc/nginx/conf.d/default.conf:ro
      depends_on:
        - backend
        - frontend
      restart: always

  telegram_bot:
    build:
      context: ./app/tg_bot/
      dockerfile: Dockerfile
    container_name: telegram_bot
    env_file:
      - .env
    volumes:
      - ./logs:/logs
    restart: on-failure
    depends_on:
      - backend

  redis:
    image: redis:latest
    ports:
      - "6379:6379"

  airflow-webserver:
    build:
      context: ./airflow
      dockerfile: Dockerfile
    container_name: airflow_web
    depends_on:
      - database
      - mlflow
    env_file:
      - .env
    environment:
      _AIRFLOW_DB_UPGRADE: 'true'
      AIRFLOW__WEBSERVER__SECRET_KEY: ${AIRFLOW__WEBSERVER__SECRET_KEY}

      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${DB_USER}:${DB_PASS}@database:5432/${DB_NAME}
      _AIRFLOW_WWW_USER_CREATE: 'true'
      _AIRFLOW_WWW_USER_USERNAME: ${_AIRFLOW_WWW_USER_USERNAME:-airflow}
      _AIRFLOW_WWW_USER_PASSWORD: ${_AIRFLOW_WWW_USER_PASSWORD:-airflow}
      SQL_ALCHEMY_CONN: postgresql+psycopg2://${DB_USER}:${DB_PASS}@database:5432/${DB_NAME}
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./worker_shared:/opt/airflow/worker_shared
      - ./models:/opt/airflow/models
      - ./mlruns:/opt/mlflow/mlruns
      - ./mlflow_artifacts:/opt/mlflow/artifacts
      - ./logs:/opt/airflow/logs
    ports:
      - '8081:8080'
    entrypoint: >
      bash -cx "
        echo '>>> Using DB:' \"${SQL_ALCHEMY_CONN}\" &&
        airflow db init &&
        airflow db upgrade &&
        exec airflow webserver
      "

  airflow-scheduler:
    build:
      context: ./airflow
      dockerfile: Dockerfile
    container_name: airflow_sched
    depends_on:
      - airflow-webserver
    env_file:
      - .env
    environment:
      SQL_ALCHEMY_CONN: postgresql+psycopg2://${DB_USER}:${DB_PASS}@database:5432/${DB_NAME}
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${DB_USER}:${DB_PASS}@database:5432/${DB_NAME}
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__WEBSERVER__SECRET_KEY: ${AIRFLOW__WEBSERVER__SECRET_KEY}
      _AIRFLOW_WWW_USER_CREATE: 'true'
      _AIRFLOW_WWW_USER_USERNAME: ${_AIRFLOW_WWW_USER_USERNAME:-airflow}
      _AIRFLOW_WWW_USER_PASSWORD: ${_AIRFLOW_WWW_USER_PASSWORD:-airflow}
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./worker_shared:/opt/airflow/worker_shared
      - ./models:/opt/airflow/models
      - ./mlruns:/opt/mlflow/mlruns
      - ./mlflow_artifacts:/opt/mlflow/artifacts
      - ./logs:/opt/airflow/logs
    entrypoint: >
      bash -cx "exec airflow scheduler"

  mlflow:
    build:
      context: opt/mlflow
      dockerfile: Dockerfile
    container_name: mlflow
    env_file:
      - .env
    volumes:
      - ./mlruns:/opt/mlflow/mlruns
      - ./mlflow_artifacts:/opt/mlflow/artifacts
    ports:
      - "5000:5000"
